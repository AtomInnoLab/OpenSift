"""Evidence Verifier — LLM-based result validation against screening criteria.

The verifier is the second stage of the OpenSift filtering funnel.  It takes
each search result (represented as a generic ``ResultItem``) and validates it
against the criteria generated by the Planner, using an LLM to produce
per-criterion assessments with evidence.

The verifier is domain-agnostic: it works with any type of search result
(academic papers, products, news articles, etc.) as long as the result is
converted to a ``ResultItem``.
"""

from __future__ import annotations

import asyncio
import logging
import time
from typing import TYPE_CHECKING

from opensift.core.llm.client import LLMClient, LLMError
from opensift.core.llm.prompts import (
    PAPER_VALIDATION_SYSTEM_PROMPT,
    PAPER_VALIDATION_USER_PROMPT,
    VALIDATION_SYSTEM_PROMPT,
    VALIDATION_USER_PROMPT,
    format_criteria_xml,
)
from opensift.models.assessment import (
    AssessmentType,
    CriterionAssessment,
    Evidence,
    ValidationResult,
)

if TYPE_CHECKING:
    from opensift.config.settings import Settings
    from opensift.models.criteria import Criterion
    from opensift.models.result import ResultItem

logger = logging.getLogger(__name__)


class EvidenceVerifier:
    """LLM-based search result validation against screening criteria.

    For each result, the verifier calls the LLM with the result's metadata
    and the criteria, producing a structured ``ValidationResult`` with
    per-criterion assessments, evidence, and a summary.

    Supports concurrent validation of multiple results.

    Attributes:
        settings: Application configuration.
    """

    def __init__(self, settings: Settings) -> None:
        self.settings = settings
        self._llm_client: LLMClient | None = None

        if settings.ai.api_key and settings.ai.api_key not in ("", "test-key"):
            self._llm_client = LLMClient(settings.ai)
            logger.info("Verifier LLM client initialized (model=%s)", settings.ai.model_verifier)
        else:
            logger.warning("Verifier LLM client NOT initialized (no API key) — using fallback")

    async def verify(
        self,
        item: ResultItem,
        criteria: list[Criterion],
        query: str,
        question_lang: str = "English",
    ) -> ValidationResult:
        """Validate a single search result against all criteria.

        Args:
            item: The search result to validate.
            criteria: Screening criteria from the planner.
            query: Original user query.
            question_lang: Language for explanations ("English" or "中文").

        Returns:
            A ValidationResult with per-criterion assessments.
        """
        if self._llm_client:
            try:
                return await self._validate_with_llm(item, criteria, query, question_lang)
            except (LLMError, Exception):
                logger.warning("LLM validation failed for result: %s", item.title[:80], exc_info=True)

        # Fallback: return insufficient_information for all criteria
        return self._fallback_validation(criteria)

    async def verify_batch(
        self,
        items: list[ResultItem],
        criteria: list[Criterion],
        query: str,
        question_lang: str = "English",
        *,
        max_concurrent: int = 5,
    ) -> list[ValidationResult]:
        """Validate multiple search results concurrently.

        Args:
            items: List of search results to validate.
            criteria: Screening criteria.
            query: Original user query.
            question_lang: Language for explanations.
            max_concurrent: Max concurrent LLM calls.

        Returns:
            List of ValidationResults in the same order as input items.
        """
        semaphore = asyncio.Semaphore(max_concurrent)

        async def _limited_verify(item: ResultItem) -> ValidationResult:
            async with semaphore:
                return await self.verify(item, criteria, query, question_lang)

        start_time = time.monotonic()
        results = await asyncio.gather(
            *[_limited_verify(item) for item in items],
            return_exceptions=True,
        )

        validated: list[ValidationResult] = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.warning("Validation failed for result %d: %s", i, result)
                validated.append(self._fallback_validation(criteria))
            else:
                validated.append(result)

        elapsed_ms = int((time.monotonic() - start_time) * 1000)
        logger.info(
            "Batch verification complete",
            extra={
                "total_results": len(items),
                "elapsed_ms": elapsed_ms,
            },
        )
        return validated

    # ── Backward-compatible aliases ──

    async def verify_paper(
        self,
        paper: object,
        criteria: list[Criterion],
        query: str,
        question_lang: str = "English",
    ) -> ValidationResult:
        """Backward-compatible alias for :meth:`verify`.

        Accepts a ``PaperInfo`` (or any object with ``to_result_item()``)
        and delegates to :meth:`verify`.
        """
        item: ResultItem = paper.to_result_item()  # type: ignore[union-attr]
        return await self.verify(item, criteria, query, question_lang)

    async def verify_papers(
        self,
        papers: list,
        criteria: list[Criterion],
        query: str,
        question_lang: str = "English",
        *,
        max_concurrent: int = 5,
    ) -> list[ValidationResult]:
        """Backward-compatible alias for :meth:`verify_batch`.

        Accepts a list of ``PaperInfo`` (or any objects with ``to_result_item()``)
        and delegates to :meth:`verify_batch`.
        """
        items: list[ResultItem] = [p.to_result_item() for p in papers]  # type: ignore[union-attr]
        return await self.verify_batch(items, criteria, query, question_lang, max_concurrent=max_concurrent)

    # ── Internal ──

    async def _validate_with_llm(
        self,
        item: ResultItem,
        criteria: list[Criterion],
        query: str,
        question_lang: str,
    ) -> ValidationResult:
        """Validate a result using the LLM.

        Automatically selects the prompt template based on
        ``item.result_type``:

        - ``"paper"`` → paper-specific prompts with fixed academic XML fields.
        - anything else → generic prompts with dynamically rendered fields.

        Args:
            item: Result to validate.
            criteria: Screening criteria.
            query: Original user query.
            question_lang: Language for output text fields.

        Returns:
            Parsed ValidationResult from LLM output.
        """
        assert self._llm_client is not None

        criteria_descriptions = [c.description for c in criteria]
        criteria_xml = format_criteria_xml(criteria_descriptions)
        current_time = time.strftime("%Y-%m-%d %H:%M:%S")

        if item.result_type == "paper":
            system_prompt, user_prompt = self._build_paper_prompt(
                item,
                criteria_xml,
                query,
                current_time,
                question_lang,
            )
        else:
            system_prompt, user_prompt = self._build_generic_prompt(
                item,
                criteria_xml,
                query,
                current_time,
                question_lang,
            )

        raw = await self._llm_client.chat_json(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            model=self.settings.ai.model_verifier,
            temperature=0.1,
        )

        return self._parse_validation_response(raw, criteria)

    @staticmethod
    def _build_paper_prompt(
        item: ResultItem,
        criteria_xml: str,
        query: str,
        current_time: str,
        question_lang: str,
    ) -> tuple[str, str]:
        """Build the paper-specific system + user prompt pair.

        Uses ``PAPER_VALIDATION_*`` templates with fixed academic XML fields.
        """
        fields = item.fields
        user_prompt = PAPER_VALIDATION_USER_PROMPT.format(
            time=current_time,
            query=query,
            criteria=criteria_xml,
            title=item.title,
            authors=fields.get("authors", "N/A"),
            affiliations=fields.get("affiliations", "N/A"),
            conference_journal=fields.get("conference_journal", "N/A"),
            conference_journal_type=fields.get("conference_journal_type", "N/A"),
            research_field=fields.get("research_field", "N/A"),
            doi=fields.get("doi", "N/A"),
            publication_date=fields.get("publication_date", "N/A"),
            abstract=item.content,
            citation_count=fields.get("citation_count", "0"),
            source_url=item.source_url,
            question_lang=question_lang,
        )
        return PAPER_VALIDATION_SYSTEM_PROMPT, user_prompt

    @staticmethod
    def _build_generic_prompt(
        item: ResultItem,
        criteria_xml: str,
        query: str,
        current_time: str,
        question_lang: str,
    ) -> tuple[str, str]:
        """Build the generic system + user prompt pair.

        Uses ``VALIDATION_*`` templates with dynamically rendered XML.
        """
        result_xml = item.to_prompt_xml()
        user_prompt = VALIDATION_USER_PROMPT.format(
            time=current_time,
            query=query,
            criteria=criteria_xml,
            result_xml=result_xml,
            question_lang=question_lang,
        )
        return VALIDATION_SYSTEM_PROMPT, user_prompt

    def _parse_validation_response(self, raw: dict, criteria: list[Criterion]) -> ValidationResult:
        """Parse LLM validation response into a ValidationResult.

        Args:
            raw: Raw JSON dict from LLM.
            criteria: The criteria list (for ID mapping).

        Returns:
            Parsed ValidationResult.
        """
        assessments_raw = raw.get("criteria_assessment", [])
        summary = raw.get("summary", "")

        assessments: list[CriterionAssessment] = []
        for i, a in enumerate(assessments_raw):
            # Map assessment string to enum
            assessment_str = a.get("assessment", "insufficient_information")
            try:
                assessment_type = AssessmentType(assessment_str)
            except ValueError:
                assessment_type = AssessmentType.INSUFFICIENT_INFORMATION

            # Parse evidence
            evidence_list: list[Evidence] = []
            for ev in a.get("evidence", []):
                evidence_list.append(
                    Evidence(
                        source=ev.get("source", "unknown"),
                        text=ev.get("text", ""),
                    )
                )

            # Determine criterion_id
            criterion_id = a.get("criterion_id", "")
            if not criterion_id and i < len(criteria):
                criterion_id = criteria[i].criterion_id

            assessments.append(
                CriterionAssessment(
                    criterion_id=criterion_id,
                    assessment=assessment_type,
                    explanation=a.get("explanation", ""),
                    evidence=evidence_list,
                )
            )

        return ValidationResult(
            criteria_assessment=assessments,
            summary=summary,
        )

    @staticmethod
    def _fallback_validation(criteria: list[Criterion]) -> ValidationResult:
        """Create a fallback validation when LLM is unavailable.

        Marks all criteria as insufficient_information.
        """
        return ValidationResult(
            criteria_assessment=[
                CriterionAssessment(
                    criterion_id=c.criterion_id,
                    assessment=AssessmentType.INSUFFICIENT_INFORMATION,
                    explanation="LLM validation unavailable — insufficient information.",
                    evidence=[],
                )
                for c in criteria
            ],
            summary="Automated validation could not be performed.",
        )
